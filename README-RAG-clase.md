# Clasificaci√≥n CIE-10 con RAG + LLMs

Script simplificado para ense√±ar **Retrieval-Augmented Generation (RAG)** con LLMs.

## üìö Conceptos que ense√±a

1. **Embeddings**: Convertir texto a vectores num√©ricos
2. **Vector Store**: Base de datos con b√∫squeda sem√°ntica
3. **RAG**: Retrieval-Augmented Generation
4. **Tool Calling**: LLM usa herramientas autom√°ticamente
5. **B√∫squeda H√≠brida**: BM25 (keywords) + VSS (embeddings)

## üöÄ Uso

```r
source("llm-classify-icd10-simple.R")
```

## üìñ Flujo del c√≥digo

### 1. Setup
- Configura LLM (Ollama con kimi-k2)
- Define textos m√©dicos de ejemplo

### 2. Carga cat√°logo CIE-10
- 1,843 c√≥digos desde JSON
- Filtra niveles 1-2 (m√°s relevantes)

### 3. Crea RAG Store
- **Primera vez**: Genera embeddings de todos los c√≥digos (~5 min)
- **Siguientes veces**: Conecta a store existente (~1 seg)
- Embeddings: `embeddinggemma:latest` (768 dimensiones)
- Store: DuckDB con extensiones FTS + VSS

### 4. Registra Tool de Retrieval
```r
ragnar_register_tool_retrieve(chat, store, top_k = 10)
```
- El LLM ahora tiene acceso a la herramienta `retrieve`
- Puede buscar c√≥digos CIE-10 cuando los necesite

### 5. Clasifica textos
```r
classify_with_rag(texto, chat)
```

**Qu√© pasa internamente:**
1. Enviamos prompt al LLM: "Clasifica este texto... usa tool 'retrieve'"
2. LLM decide usar `retrieve("tumor maligno pulm√≥n")`
3. Ragnar:
   - Convierte query ‚Üí embedding (768 dims)
   - Busca en vector store (BM25 + VSS)
   - Devuelve top-10 c√≥digos al LLM
4. LLM selecciona el c√≥digo m√°s apropiado
5. Responde con JSON: `{"code":"C34.9"}`

### 6. Muestra resultados

## üéØ Ventajas de RAG

| Sin RAG | Con RAG |
|---------|---------|
| Pasar 1,843 c√≥digos en el prompt | Solo recuperar 10 relevantes |
| ~500K tokens por consulta | ~5K tokens por consulta |
| LLM se confunde con tanto contexto | LLM enfocado en opciones relevantes |
| Costo alto | Costo bajo |

## üîß Requisitos

- Ollama instalado y corriendo
- Modelos descargados:
  - `ollama pull kimi-k2:1t-cloud`
  - `ollama pull embeddinggemma:latest`
- Paquetes R: `mall`, `ellmer`, `ragnar`, `tidyverse`, `jsonlite`, `duckdb`
- Archivo: `raw-data/cie10-codes.json`

### Instalar extensiones de DuckDB (primera vez)

```r
library(duckdb)
con <- dbConnect(duckdb())
dbExecute(con, "INSTALL fts")  # Full-Text Search
dbExecute(con, "INSTALL vss")  # Vector Similarity Search
dbDisconnect(con)
```

**Esto solo se hace UNA vez.** Las extensiones quedan instaladas en tu sistema.

## üìä Output esperado

```
RESULTADOS
======================================================================

texto                                          codigo  descripcion
tumor maligno intestino delgado...            C17.9   Tumor maligno del intestino delgado, parte no especificada
diabetes mellitus tipo 2...                   E11.9   Diabetes mellitus tipo 2, sin complicaciones
adenoma benigno prostata...                   D29.1   Adenoma benigno de la pr√≥stata
...

======================================================================
RESUMEN
======================================================================
Textos clasificados: 10
C√≥digos √∫nicos: 10
```

## üß† Para la clase

**Puntos clave a destacar:**

1. **Embeddings vs Keywords**:
   - "tumor maligno" y "neoplasia maligna" tienen embeddings similares
   - B√∫squeda por keywords fallar√≠a

2. **Tool Calling**:
   - El LLM DECIDE cu√°ndo buscar
   - Puede hacer m√∫ltiples b√∫squedas si necesita refinar

3. **Escalabilidad**:
   - Con 10 c√≥digos: puede pasar todos en prompt
   - Con 10,000 c√≥digos: RAG es esencial

4. **B√∫squeda h√≠brida**:
   - BM25: Detecta keywords exactas ("maligno" vs "benigno")
   - VSS: Similitud sem√°ntica ("c√°ncer" ‚âà "neoplasia")

## üìù Ejercicios para estudiantes

1. Agregar m√°s textos m√©dicos y ver c√≥mo clasifica
2. Cambiar `top_k` (5, 10, 20) y comparar resultados
3. Probar con otros dominios (legal, t√©cnico, etc.)
4. Medir tiempo de ejecuci√≥n con/sin cache
5. Comparar con approach sin RAG (pasar todos los c√≥digos)
